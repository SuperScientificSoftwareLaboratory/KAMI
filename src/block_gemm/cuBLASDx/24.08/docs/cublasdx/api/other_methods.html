<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Other Methods &mdash; cuBLASDx 0.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/cublasdx_override.css" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Other" href="other.html" />
    <link rel="prev" title="Execution Methods" href="methods.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" > 

          
          
          <a href="../index.html" class="icon icon-home">
            cuBLASDx
          </a>
              <div class="version">
                0.2.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

  <style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search, .wy-nav-top {
      background: #76b900;
    }

    .wy-side-nav-search a:link, .wy-nav-top a:link {
      color: #fff;
    }
    .wy-side-nav-search a:visited, .wy-nav-top a:visited {
      color: #fff;
    }
    .wy-side-nav-search a:hover, .wy-nav-top a:hover {
      color: #fff;
    }

    .wy-menu-vertical a:link, .wy-menu-vertical a:visited {
      color: #d9d9d9
    }

    .wy-menu-vertical a:active {
      background-color: #76b900
    }

    .wy-side-nav-search>div.version {
      color: rgba(0, 0, 0, 0.3)
    }

    /* override table width restrictions */
    .wy-table-responsive table td, .wy-table-responsive table th {
        white-space: normal;
    }

    .wy-table-responsive {
        margin-bottom: 24px;
        max-width: 100%;
        overflow: visible;
    }
  </style>
  
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Documentation home</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User guide:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../requirements_func.html">Requirements and Functionality</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../requirements_func.html#requirements">Requirements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../requirements_func.html#supported-compilers">Supported Compilers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../requirements_func.html#supported-functionality">Supported Functionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="../requirements_func.html#supported-gemm-data-types">Supported GEMM Data Types</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Quick Installation Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#cublasdx-in-your-project">cuBLASDx In Your Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#cublasdx-in-your-cmake-project">cuBLASDx In Your CMake Project</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../installation.html#using-custom-cutlass">Using Custom CUTLASS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../installation.html#defined-variables">Defined Variables</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../introduction1.html">General Matrix Multiply Using cuBLASDx</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../introduction1.html#defining-gemm-operation">Defining GEMM Operation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction1.html#executing-gemm">Executing GEMM</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../introduction1.html#tensor-creation">Tensor Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../introduction1.html#copying-tensors">Copying Tensors</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../introduction1.html#launching-gemm-kernel">Launching GEMM Kernel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../introduction1.html#compilation">Compilation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Achieving High Performance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../performance.html#general-advice">General Advice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../performance.html#matrix-layouts">Matrix Layouts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../performance.html#memory-management">Memory Management</a></li>
<li class="toctree-l2"><a class="reference internal" href="../performance.html#advanced">Advanced</a></li>
<li class="toctree-l2"><a class="reference internal" href="../performance.html#further-reading">Further Reading</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../performance.html#references">References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="operators.html">Operators</a><ul>
<li class="toctree-l3"><a class="reference internal" href="operators.html#description-operators">Description Operators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="operators.html#size-operator">Size Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#type-operator">Type Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#precision-operator">Precision Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#arrangement-operator">Arrangement Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#transposemode-operator">TransposeMode Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#leadingdimension-operator">LeadingDimension Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#alignment-operator">Alignment Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#function-operator">Function Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#sm-operator">SM Operator</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="operators.html#execution-operators">Execution Operators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="operators.html#block-operator">Block Operator</a></li>
<li class="toctree-l4"><a class="reference internal" href="operators.html#block-configuration-operators">Block Configuration Operators</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="traits.html">Traits</a><ul>
<li class="toctree-l3"><a class="reference internal" href="traits.html#description-traits">Description Traits</a><ul>
<li class="toctree-l4"><a class="reference internal" href="traits.html#size-trait">Size Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#type-trait">Type Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#precision-trait">Precision Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#function-trait">Function Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#arrangement-trait">Arrangement Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#transpose-mode-trait">Transpose Mode Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#alignment-trait">Alignment Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#suggested-alignment-trait">Suggested Alignment Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#sm-trait">SM Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#is-blas-trait">is_blas Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#is-blas-execution-trait">is_blas_execution Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#is-complete-blas-trait">is_complete_blas Trait</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#is-complete-blas-execution-trait">is_complete_blas_execution Trait</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="traits.html#execution-traits">Execution Traits</a><ul>
<li class="toctree-l4"><a class="reference internal" href="traits.html#block-traits">Block Traits</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="traits.html#other-traits">Other Traits</a><ul>
<li class="toctree-l4"><a class="reference internal" href="traits.html#is-supported">is_supported</a></li>
<li class="toctree-l4"><a class="reference internal" href="traits.html#suggested-leading-dimension-of">suggested_leading_dimension_of</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="methods.html">Execution Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="methods.html#block-execute-method">Block Execute Method</a><ul>
<li class="toctree-l4"><a class="reference internal" href="methods.html#value-format">Value Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="methods.html#input-output-data-format">Input/Output Data Format</a></li>
<li class="toctree-l4"><a class="reference internal" href="methods.html#shared-memory-usage">Shared Memory Usage</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Other Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#shared-memory-slicing">Shared Memory Slicing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#get-memory-layout">Get Memory Layout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#suggested-shared-memory-layout">Suggested Shared Memory Layout</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="other.html">Other</a><ul>
<li class="toctree-l3"><a class="reference internal" href="other.html#tensor">Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="other.html#tensor-creation">Tensor Creation</a></li>
<li class="toctree-l3"><a class="reference internal" href="other.html#copying-tensors">Copying Tensors</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#introduction-examples">Introduction Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#simple-gemm-examples">Simple GEMM Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#nvrtc-examples">NVRTC Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#gemm-performance">GEMM Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../examples.html#advanced-examples">Advanced Examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../release_notes.html#id1">0.2.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../release_notes.html#new-features">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes.html#known-issues">Known Issues</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../release_notes.html#id2">0.1.0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../release_notes.html#id3">New Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../release_notes.html#id4">Known Issues</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../license.html">Software License Agreement</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../license.html#third-party-license-agreements">Third Party License Agreements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../license.html#cutlass">CUTLASS</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">cuBLASDx</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">API reference</a></li>
      <li class="breadcrumb-item active">Other Methods</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="other-methods">
<h1>Other Methods<a class="headerlink" href="#other-methods" title="Permalink to this heading">¶</a></h1>
<div class="section" id="shared-memory-slicing">
<span id="slice-shared-memory-other-label"></span><h2>Shared Memory Slicing<a class="headerlink" href="#shared-memory-slicing" title="Permalink to this heading">¶</a></h2>
<p>The shared memory slicing methods are available if <a class="reference internal" href="traits.html#isblascompleteexecution-trait-label"><span class="std std-ref">is_complete_blas_execution Trait</span></a> is <code class="code highlight cpp docutils literal highlight-cpp"><span class="nb">true</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Note: When using NVRTC std::tuple is replaced with cuda::std::tuple</span>

<span class="c1">// #1</span>
<span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">BLAS</span><span class="o">::</span><span class="n">a_value_type</span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">b_value_type</span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">c_value_type</span><span class="o">*&gt;</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">smem_ptr</span><span class="p">)</span>

<span class="c1">// #2: Slice shared memory with dynamic leading dimensions</span>
<span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">BLAS</span><span class="o">::</span><span class="n">a_value_type</span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">b_value_type</span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">c_value_type</span><span class="o">*&gt;</span>
<span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">smem_ptr</span><span class="p">,</span>
<span class="w">                          </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lda</span><span class="p">,</span>
<span class="w">                          </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">ldb</span><span class="p">,</span>
<span class="w">                          </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">ldc</span><span class="p">)</span>

<span class="c1">// #3: Slice shared memory with custom matrices layouts</span>
<span class="k">template</span><span class="o">&lt;</span><span class="k">class</span><span class="w"> </span><span class="nc">ALayout</span><span class="p">,</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">BLayout</span><span class="p">,</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">CLayout</span><span class="o">&gt;</span>
<span class="n">std</span><span class="o">::</span><span class="n">tuple</span><span class="o">&lt;</span><span class="n">BLAS</span><span class="o">::</span><span class="n">a_value_type</span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">b_value_type</span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">c_value_type</span><span class="o">*&gt;</span>
<span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">(</span><span class="kt">char</span><span class="o">*</span><span class="w"> </span><span class="n">smem_ptr</span><span class="p">,</span>
<span class="w">                          </span><span class="n">ALayout</span><span class="w"> </span><span class="n">a_layout</span><span class="p">,</span>
<span class="w">                          </span><span class="n">BLayout</span><span class="w"> </span><span class="n">b_layout</span><span class="p">,</span>
<span class="w">                          </span><span class="n">CLayout</span><span class="w"> </span><span class="n">c_layout</span><span class="p">)</span>
</pre></div>
</div>
<p>Method <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">slice_shared_memory</span><span class="p">(...)</span></code> slices shared memory into chunks, one for each matrix.</p>
<p>The return values are pointers to the first element of the slices for <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code> and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code> matrices.
They follow the <a class="reference internal" href="traits.html#alignment-exec-trait-label"><span class="std std-ref">alignments</span></a> in <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BLAS</span></code> description and at the same time, are not over-aligned, i.e., bytes between two slices are less
than the alignments. Same as <a class="reference internal" href="traits.html#sharedmemory-block-trait-label"><span class="std std-ref">Shared Memory Size Trait</span></a>, the result depends on <a class="reference internal" href="traits.html#valuetype-block-trait-label"><span class="std std-ref">value types</span></a>
and <a class="reference internal" href="traits.html#matrixsize-block-trait-label"><span class="std std-ref">matrix sizes</span></a>.</p>
<p>Note that <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span></code> accepts arbitrary <a class="reference external" href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/01_layout.md">CuTe layouts</a>.
Class <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">ALayout</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BLayout</span></code> and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">CLayout</span></code> in the above function prototype could be either
<a class="reference external" href="https://github.com/NVIDIA/cutlass/blob/main/include/cute/layout.hpp">cute::Layout</a> or
<a class="reference external" href="https://github.com/NVIDIA/cutlass/blob/main/include/cute/layout_composed.hpp">cute::ComposedLayout</a>.</p>
<div class="hint admonition">
<p class="admonition-title">Example</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">BLAS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">decltype</span><span class="p">(...);</span>

<span class="k">extern</span><span class="w"> </span><span class="n">__shared__</span><span class="w"> </span><span class="nf">__align__</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="n">smem</span><span class="p">[];</span>

<span class="c1">// use structured binding</span>
<span class="k">auto</span><span class="w"> </span><span class="p">[</span><span class="n">smem_a</span><span class="p">,</span><span class="w"> </span><span class="n">smem_b</span><span class="p">,</span><span class="w"> </span><span class="n">smem_c</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">();</span>

<span class="c1">// or</span>
<span class="k">auto</span><span class="w"> </span><span class="n">smem_slices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">smem_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sliced_smem</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">smem_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sliced_smem</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">smem_c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sliced_smem</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When using NVRTC, libcu++ (libcudacxx) is used and <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">std</span><span class="o">::</span></code> is replaced with <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">cuda</span><span class="o">::</span><span class="n">std</span><span class="o">::</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">BLAS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">decltype</span><span class="p">(...);</span>

<span class="k">extern</span><span class="w"> </span><span class="n">__shared__</span><span class="w"> </span><span class="nf">__align__</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="n">smem</span><span class="p">[];</span>

<span class="c1">// Structured bindings support for cuda::std::tuple was added in 2.1.0 version of libcu++</span>
<span class="cp">#if _LIBCUDACXX_CUDA_API_VERSION &gt;= 2001000</span>
<span class="k">auto</span><span class="w"> </span><span class="p">[</span><span class="n">smem_a</span><span class="p">,</span><span class="w"> </span><span class="n">smem_b</span><span class="p">,</span><span class="w"> </span><span class="n">smem_c</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">();</span>
<span class="cp">#else</span>
<span class="k">auto</span><span class="w"> </span><span class="n">smem_slices</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">();</span>
<span class="k">auto</span><span class="w"> </span><span class="n">smem_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">0</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sliced_smem</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">smem_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">1</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sliced_smem</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">smem_c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">get</span><span class="o">&lt;</span><span class="mi">2</span><span class="o">&gt;</span><span class="p">(</span><span class="n">sliced_smem</span><span class="p">);</span>
<span class="cp">#endif</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="get-memory-layout">
<span id="get-layout-other-label"></span><h2>Get Memory Layout<a class="headerlink" href="#get-memory-layout" title="Permalink to this heading">¶</a></h2>
<p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_</span><span class="o">&lt;</span><span class="n">gmem</span><span class="o">/</span><span class="n">smem</span><span class="o">&gt;</span><span class="n">_</span><span class="o">&lt;</span><span class="n">a</span><span class="o">/</span><span class="n">b</span><span class="o">/</span><span class="n">c</span><span class="o">&gt;</span><span class="p">()</span></code> function fetches global memory or shared memory CuTe layout for matrix <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code> or <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code>,
determined by <a class="reference internal" href="traits.html#matrixsize-block-trait-label"><span class="std std-ref">matrix sizes</span></a>, <a class="reference internal" href="operators.html#arrangement-operator-label"><span class="std std-ref">arrangement</span></a>,
and <a class="reference internal" href="operators.html#leadingdimension-operator-label"><span class="std std-ref">leading dimensions</span></a>. For shared memory layouts the leading dimensions, if not specified
explicitly through a parameter, will be inferred from the <a class="reference internal" href="operators.html#leadingdimension-operator-label"><span class="std std-ref">leading dimensions</span></a> operator. For
global memory layouts custom leading dimensions must be passed either through a static or dynamic integral type, or otherwise
they will be inferred from <a class="reference internal" href="traits.html#matrixsize-block-trait-label"><span class="std std-ref">matrix sizes</span></a>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_a</span><span class="p">();</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_b</span><span class="p">();</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_c</span><span class="p">();</span>

<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_smem_a</span><span class="p">();</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_smem_b</span><span class="p">();</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_smem_c</span><span class="p">();</span>

<span class="c1">// Overloads for specifying the leading dimensions statically during compilation time.</span>
<span class="c1">// integral_type can be either signed or unsigned integer type and integral_value follow</span>
<span class="c1">// this specification.</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_a</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">integral_constant</span><span class="o">&lt;</span><span class="n">integral_type</span><span class="p">,</span><span class="w"> </span><span class="n">lda</span><span class="o">&gt;</span><span class="p">);</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_b</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">integral_constant</span><span class="o">&lt;</span><span class="n">integral_type</span><span class="p">,</span><span class="w"> </span><span class="n">ldb</span><span class="o">&gt;</span><span class="p">);</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_c</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">integral_constant</span><span class="o">&lt;</span><span class="n">integral_type</span><span class="p">,</span><span class="w"> </span><span class="n">ldc</span><span class="o">&gt;</span><span class="p">);</span>

<span class="c1">// Overloads for specifying the leading dimensions during the execution time.</span>

<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_a</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lda</span><span class="p">);</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_b</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">ldb</span><span class="p">);</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_gmem_c</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">ldc</span><span class="p">);</span>

<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_smem_a</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">lda</span><span class="p">);</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_smem_b</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">ldb</span><span class="p">);</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w">  </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">get_layout_smem_c</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">unsigned</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">ldc</span><span class="p">);</span>
</pre></div>
</div>
<p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_</span><span class="o">&lt;</span><span class="n">gmem</span><span class="o">/</span><span class="n">smem</span><span class="o">&gt;</span><span class="n">_</span><span class="o">&lt;</span><span class="n">a</span><span class="o">/</span><span class="n">b</span><span class="o">/</span><span class="n">c</span><span class="o">&gt;</span><span class="p">()</span></code> returns a combination of memory tag (global or shared) and the layout
(<a class="reference external" href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/cute/01_layout.md">cute::Layout</a>)
for matrix <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code> or <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code> which can be directly passed to <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span></code> to create a tensor.</p>
<p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_</span><span class="o">&lt;</span><span class="n">gmem</span><span class="o">/</span><span class="n">smem</span><span class="o">&gt;</span><span class="n">_</span><span class="o">&lt;</span><span class="n">a</span><span class="o">/</span><span class="n">b</span><span class="o">/</span><span class="n">c</span><span class="o">&gt;</span><span class="p">()</span></code> returns a matrix layout corresponding to the order set via
<a class="reference internal" href="operators.html#arrangement-operator-label"><span class="std std-ref">Arrangement</span></a> operator. For example, if the order for A matrix was set to <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">cublasdx</span><span class="o">::</span><span class="n">row</span><span class="o">-</span><span class="n">major</span></code>,
the returned layout follows the row-major order.</p>
<p>In case of dynamic leading dimensions provided by user during execution time, the function accepts the leading
dimension as an argument, see the example below.</p>
<div class="hint admonition">
<p class="admonition-title">Example</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">BLAS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">decltype</span><span class="p">(...)</span>

<span class="k">extern</span><span class="w"> </span><span class="n">__shared__</span><span class="w"> </span><span class="n">__align__</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="n">smem</span><span class="p">[];</span>

<span class="c1">// a, b, c are pointers to global memory of input matrices A and B and output matrix C</span>
<span class="k">auto</span><span class="w"> </span><span class="n">a_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_a</span><span class="p">());</span>
<span class="k">auto</span><span class="w"> </span><span class="n">b_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_b</span><span class="p">());</span>
<span class="k">auto</span><span class="w"> </span><span class="n">c_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_c</span><span class="p">());</span>

<span class="k">auto</span><span class="w"> </span><span class="p">[</span><span class="n">smem_a</span><span class="p">,</span><span class="w"> </span><span class="n">smem_b</span><span class="p">,</span><span class="w"> </span><span class="n">smem_c</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">(</span><span class="n">smem</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">a_shared_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_a</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_smem_a</span><span class="p">());</span>
<span class="k">auto</span><span class="w"> </span><span class="n">b_shared_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_b</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_smem_b</span><span class="p">());</span>
<span class="k">auto</span><span class="w"> </span><span class="n">c_shared_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_c</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_smem_c</span><span class="p">());</span>

<span class="c1">// With leading dimensions specified during the compilation time</span>
<span class="k">auto</span><span class="w"> </span><span class="n">a_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_a</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">integral_constant</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="n">lda</span><span class="o">&gt;</span><span class="p">{}));</span>
<span class="k">auto</span><span class="w"> </span><span class="n">b_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_b</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">integral_constant</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="n">ldb</span><span class="o">&gt;</span><span class="p">{}));</span>
<span class="k">auto</span><span class="w"> </span><span class="n">c_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_c</span><span class="p">(</span><span class="n">std</span><span class="o">::</span><span class="n">integral_constant</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span><span class="w"> </span><span class="n">ldc</span><span class="o">&gt;</span><span class="p">{}));</span>

<span class="c1">// With leading dimensions specified during the execution time</span>
<span class="k">auto</span><span class="w"> </span><span class="n">a_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_a</span><span class="p">(</span><span class="n">lda</span><span class="p">));</span>
<span class="k">auto</span><span class="w"> </span><span class="n">b_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_b</span><span class="p">(</span><span class="n">ldb</span><span class="p">));</span>
<span class="k">auto</span><span class="w"> </span><span class="n">c_global_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_gmem_c</span><span class="p">(</span><span class="n">ldc</span><span class="p">));</span>

<span class="k">auto</span><span class="w"> </span><span class="p">[</span><span class="n">smem_a</span><span class="p">,</span><span class="w"> </span><span class="n">smem_b</span><span class="p">,</span><span class="w"> </span><span class="n">smem_c</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">(</span><span class="n">smem</span><span class="p">,</span><span class="w"> </span><span class="n">lda</span><span class="p">,</span><span class="w"> </span><span class="n">ldb</span><span class="p">,</span><span class="w"> </span><span class="n">ldc</span><span class="p">);</span>
<span class="k">auto</span><span class="w"> </span><span class="n">a_shared_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_a</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_smem_a</span><span class="p">(</span><span class="n">lda</span><span class="p">));</span>
<span class="k">auto</span><span class="w"> </span><span class="n">b_shared_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_b</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_smem_b</span><span class="p">(</span><span class="n">ldb</span><span class="p">));</span>
<span class="k">auto</span><span class="w"> </span><span class="n">c_shared_tensor</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_c</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">get_layout_smem_c</span><span class="p">(</span><span class="n">ldc</span><span class="p">));</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="suggested-shared-memory-layout">
<span id="suggest-layout-other-label"></span><h2>Suggested Shared Memory Layout<a class="headerlink" href="#suggested-shared-memory-layout" title="Permalink to this heading">¶</a></h2>
<p>In addition to <a class="reference internal" href="#get-layout-other-label"><span class="std std-ref">get_layout_smem_*</span></a> function, cuBLASDx also provides a function that returns the suggested
custom shared memory layouts for matrix <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code>, <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code> or <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">C</span></code>, determined by the <a class="reference internal" href="traits.html#valuetype-block-trait-label"><span class="std std-ref">value types</span></a>,
<a class="reference internal" href="traits.html#matrixsize-block-trait-label"><span class="std std-ref">matrix sizes</span></a>, <a class="reference internal" href="operators.html#arrangement-operator-label"><span class="std std-ref">arrangements</span></a>, <a class="reference internal" href="traits.html#alignment-exec-trait-label"><span class="std std-ref">alignments</span></a>,
block size, and GPU architecture.
Those suggested layouts were designed to positively impact the performance of matrix multiplication itself as well as copy operations
between shared and global memory, and because of that they rely on the arrangements of the matrices.
Suggested layouts ignore leading dimensions set with <a class="reference internal" href="operators.html#leadingdimension-operator-label"><span class="std std-ref">LeadingDimension</span></a> operator.
The best improvements are expected with row-major <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">A</span></code> and column-major <code class="code highlight cpp docutils literal highlight-cpp"><span class="n">B</span></code>.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">suggest_layout_smem_a</span><span class="p">();</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">suggest_layout_smem_b</span><span class="p">();</span>
<span class="n">__forceinline__</span><span class="w"> </span><span class="n">__host__</span><span class="w"> </span><span class="n">__device__</span><span class="w"> </span><span class="k">constexpr</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">auto</span><span class="w"> </span><span class="n">suggest_layout_smem_c</span><span class="p">();</span>
</pre></div>
</div>
<p><code class="code highlight cpp docutils literal highlight-cpp"><span class="n">BLAS</span><span class="o">::</span><span class="n">suggest_layout_smem_</span><span class="o">&lt;</span><span class="n">a</span><span class="o">/</span><span class="n">b</span><span class="o">/</span><span class="n">c</span><span class="o">&gt;</span><span class="p">()</span></code> returns a combination of a shared memory tag and the layout of A/B/C (<code class="code highlight cpp docutils literal highlight-cpp"><span class="n">cute</span><span class="o">::</span><span class="n">Layout</span></code>),
which can be directly passed to <a class="reference internal" href="other.html#create-tensor-other-label"><span class="std std-ref">cublasdx::make_tensor</span></a> to create a tensor.</p>
<div class="hint admonition">
<p class="admonition-title">Example</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">BLAS</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">decltype</span><span class="p">(</span><span class="n">Size</span><span class="o">&lt;</span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">128</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Type</span><span class="o">&lt;</span><span class="n">type</span><span class="o">::</span><span class="n">real</span><span class="o">&gt;</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Block</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Precision</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="kt">float</span><span class="p">,</span><span class="w"> </span><span class="kt">double</span><span class="o">&gt;</span><span class="p">());</span>

<span class="k">extern</span><span class="w"> </span><span class="n">__shared__</span><span class="w"> </span><span class="nf">__align__</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="n">smem</span><span class="p">[];</span>

<span class="c1">// Slice shared memory into pointer for A, B, and C matrices</span>
<span class="k">auto</span><span class="w"> </span><span class="p">[</span><span class="n">smem_a</span><span class="p">,</span><span class="w"> </span><span class="n">smem_b</span><span class="p">,</span><span class="w"> </span><span class="n">smem_c</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">slice_shared_memory</span><span class="p">(</span><span class="n">smem</span><span class="p">);</span>

<span class="c1">// Create suggested shared memory layout for optimal performance</span>
<span class="k">auto</span><span class="w"> </span><span class="n">suggested_smem_a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_a</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">suggest_layout_smem_a</span><span class="p">());</span>
<span class="k">auto</span><span class="w"> </span><span class="n">suggested_smem_b</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_b</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">suggest_layout_smem_b</span><span class="p">());</span>
<span class="k">auto</span><span class="w"> </span><span class="n">suggested_smem_c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cublasdx</span><span class="o">::</span><span class="n">make_tensor</span><span class="p">(</span><span class="n">smem_c</span><span class="p">,</span><span class="w"> </span><span class="n">BLAS</span><span class="o">::</span><span class="n">suggest_layout_smem_c</span><span class="p">());</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="methods.html" class="btn btn-neutral float-left" title="Execution Methods" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="other.html" class="btn btn-neutral float-right" title="Other" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">

<p style="color: gray;">
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-policy/" target="_blank" style="color: inherit;">Privacy Policy</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/privacy-center/" target="_blank" style="color: inherit;">Manage My Privacy</a>
|
<a href="https://www.nvidia.com/en-us/preferences/start/" target="_blank" style="color: inherit;">Do Not Sell or Share My Data</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/terms-of-service/" target="_blank" style="color: inherit;">Terms of Service</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/accessibility/" target="_blank" style="color: inherit;">Accessibility</a>
|
<a href="https://www.nvidia.com/en-us/about-nvidia/company-policies/" target="_blank" style="color: inherit;">Corporate Policies</a>
|
<a href="https://www.nvidia.com/en-us/product-security/" target="_blank" style="color: inherit;">Product Security</a>
|
<a href="https://www.nvidia.com/en-us/contact/" target="_blank" style="color: inherit;">Contact</a>
</p>

<p>
  Copyright &#169; 2022-2024, NVIDIA Corporation &amp; Affiliates. All rights reserved.
</p>

    <p></p>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

  <style>
  a:link, a:visited {
    color: #76b900;
  }

  a:hover {
    color: #8c0;
  }

  .rst-content dl:not(.docutils) dt {
    background: rgba(118, 185, 0, 0.1);
    color: rgba(59,93,0,1);
    border-top: solid 3px rgba(59,93,0,1);
  }
  </style>
  

</body>
</html>